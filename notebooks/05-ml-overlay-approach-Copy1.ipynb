{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2823faa8-cbb4-4921-92f9-7cfa0d0f3b97",
   "metadata": {},
   "source": [
    "## Overlay on Sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693ab7f8-86b0-46c1-94db-23f70803a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import umap.umap_ as umap\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import low_pass_filter, high_pass_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5b9e5d4-17a5-4388-afec-e7a4df6bfa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "office_features_path = \"../features/office/extracted-features.csv\"\n",
    "office_segments_dir = \"../data/segments/office/\"\n",
    "\n",
    "nature_features_path = \"../features/nature/extracted-features.csv\"\n",
    "nature_segments_dir = \"../data/segments/nature/\"\n",
    "\n",
    "augmented_output_dir = \"../data/transformation-strategies/augmented_overlay/\"\n",
    "os.makedirs(augmented_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893aac31-2a55-4f68-b17c-3a31e48ff6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Office features: (644, 9)\n",
      "Nature features: (2379, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load features\n",
    "office_df = pd.read_csv(office_features_path)\n",
    "nature_df = pd.read_csv(nature_features_path)\n",
    "\n",
    "# Inspect\n",
    "print(\"Office features:\", office_df.shape)\n",
    "print(\"Nature features:\", nature_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7209ff7e-f41f-4db0-9983-88f3dc81f4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "nature-5     1739\n",
       "nature-7      136\n",
       "nature-6      122\n",
       "nature-8      121\n",
       "nature-9      120\n",
       "nature-10      72\n",
       "nature-3       26\n",
       "nature-1       17\n",
       "nature-2       16\n",
       "nature-4       10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Define \n",
    "interesting_files = [\"segment_139.wav\" \"segment_397.wav\", \"segment_356.wav\", \n",
    "                     \"segment_051.wav\", \"segment_050.wav\", \"segment_170.wav\", \n",
    "                     \"segment_034.wav\", \"segment_087.wav\"]\n",
    "\n",
    "file_qualities = [\"Loudest\", \"Softest\", \"Brightest & Noisiest\",\n",
    "                   \"Dullest\", \"Smoothest\", \"Normal\",\n",
    "                   \"Normal\", \"Normal\"]\n",
    "\n",
    "# Parameters\n",
    "window_ms = 300       # Window size\n",
    "step_ms = 150         # Step size (50% overlap)\n",
    "threshold_db = -30    # Overlay only above this level\n",
    "highpass_hz = 300\n",
    "lowpass_hz = 7000\n",
    "ambient_gain_offset = -3  # dB softer than office\n",
    "\n",
    "# === Prepare Cluster Mapping ===\n",
    "file_to_cluster = dict(zip(office_df[\"filename\"], office_df[\"cluster\"]))\n",
    "\n",
    "# === Process Each File ===\n",
    "for office_filename in interesting_files:\n",
    "    cluster_id = file_to_cluster.get(office_filename)\n",
    "    if cluster_id is None:\n",
    "        print(f\"Skipping {office_filename} (no cluster info)\")\n",
    "        continue\n",
    "\n",
    "    match_row = cluster_match_df[cluster_match_df[\"cluster_id\"] == cluster_id].iloc[0]\n",
    "    ambient_source = match_row[\"ambient_source\"]\n",
    "    ambient_filename = match_row[\"ambient_filename\"]\n",
    "\n",
    "    office_path = os.path.join(office_segments_dir, office_filename)\n",
    "    ambient_path = os.path.join(nature_segments_dir, ambient_source, ambient_filename)\n",
    "\n",
    "    try:\n",
    "        office_audio = AudioSegment.from_wav(office_path)\n",
    "        ambient_audio = AudioSegment.from_wav(ambient_path)\n",
    "\n",
    "        # Match length\n",
    "        ambient_audio *= (len(office_audio) // len(ambient_audio)) + 1\n",
    "        ambient_audio = ambient_audio[:len(office_audio)]\n",
    "\n",
    "        # Filter and soften\n",
    "        ambient_audio = high_pass_filter(ambient_audio, highpass_hz)\n",
    "        ambient_audio = low_pass_filter(ambient_audio, lowpass_hz)\n",
    "        ambient_audio = ambient_audio - 3\n",
    "\n",
    "        output = AudioSegment.silent(duration=len(office_audio))\n",
    "\n",
    "        for i in range(0, len(office_audio) - window_ms, step_ms):\n",
    "            slice_office = office_audio[i:i+window_ms]\n",
    "            slice_ambient = ambient_audio[i:i+window_ms]\n",
    "\n",
    "            if slice_office.dBFS > threshold_db:\n",
    "                gain_db = 10 * np.log10((slice_office.rms or 1) / (slice_ambient.rms or 1)) + ambient_gain_offset\n",
    "                slice_ambient = slice_ambient + gain_db\n",
    "                mixed = slice_office.overlay(slice_ambient)\n",
    "            else:\n",
    "                mixed = slice_office\n",
    "\n",
    "            output = output.overlay(mixed, position=i)\n",
    "\n",
    "        out_name = f\"match_{office_filename}\"\n",
    "        out_path = os.path.join(augmented_output_dir, out_name)\n",
    "        output.export(out_path, format=\"wav\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {office_filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7ee03-5945-436d-a9a7-db1ac32d922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, HTML, display\n",
    "import os\n",
    "\n",
    "# Define your files and their quality labels\n",
    "interesting_files = [\n",
    "    \"segment_139.wav\", \"segment_397.wav\", \"segment_356.wav\", \n",
    "    \"segment_051.wav\", \"segment_050.wav\", \"segment_170.wav\", \n",
    "    \"segment_034.wav\", \"segment_087.wav\"\n",
    "]\n",
    "\n",
    "file_qualities = [\n",
    "    \"Loudest\", \"Softest\", \"Brightest & Noisiest\",\n",
    "    \"Dullest\", \"Smoothest\", \"Normal\",\n",
    "    \"Normal\", \"Normal\"\n",
    "]\n",
    "\n",
    "# Define your folders\n",
    "original_path = \"../data/segments/office/\"\n",
    "augmented_path = \"../data/transformation-strategies/augmented_overlay/\"\n",
    "\n",
    "# Build HTML table\n",
    "table_rows = []\n",
    "for fname, quality in zip(interesting_files, file_qualities):\n",
    "    orig_file = os.path.join(original_path, fname)\n",
    "    aug_file = os.path.join(augmented_path, f\"match_{fname}\")\n",
    "    \n",
    "    # Make sure both files exist\n",
    "    if os.path.exists(orig_file) and os.path.exists(aug_file):\n",
    "        row = f\"\"\"\n",
    "        <tr>\n",
    "            <td><b>{fname}</b><br><i>{quality}</i></td>\n",
    "            <td>{Audio(orig_file)._repr_html_()}</td>\n",
    "            <td>{Audio(aug_file)._repr_html_()}</td>\n",
    "        </tr>\n",
    "        \"\"\"\n",
    "        table_rows.append(row)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing file: {fname}\")\n",
    "\n",
    "# Full HTML\n",
    "html = f\"\"\"\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>File & Quality</th>\n",
    "            <th>Original</th>\n",
    "            <th>Augmented</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        {''.join(table_rows)}\n",
    "    </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "# Display in notebook\n",
    "display(HTML(html))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
